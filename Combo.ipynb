{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T00:55:29.634322Z",
     "start_time": "2019-05-02T00:55:29.628323Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reference: https://www.pyimagesearch.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T18:45:20.377939Z",
     "start_time": "2019-04-29T18:45:19.634366Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T19:29:47.104833Z",
     "start_time": "2019-04-29T19:29:47.097837Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T18:45:47.014134Z",
     "start_time": "2019-04-29T18:45:43.273815Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T18:45:56.953148Z",
     "start_time": "2019-04-29T18:45:56.949149Z"
    }
   },
   "outputs": [],
   "source": [
    "image_shape = (32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T18:46:05.280495Z",
     "start_time": "2019-04-29T18:46:05.270500Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_outliers(dfs):\n",
    "    \n",
    "    df = dfs.copy(deep=True)\n",
    "    zipcodes = list(df['zip_code'].value_counts().keys())\n",
    "    counts = list(df[\"zip_code\"].value_counts())\n",
    "\n",
    "    df_new = pd.DataFrame()\n",
    "    for (zipcode, count) in zip(zipcodes, counts):\n",
    "        if count > 25:\n",
    "            ind = df[df['zip_code'] == zipcode].index\n",
    "            for i in ind:\n",
    "                df_new = df_new.append(df[i:i+1])\n",
    "            \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T18:46:15.579118Z",
     "start_time": "2019-04-29T18:46:15.561110Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_images(df):\n",
    "    \n",
    "    \n",
    "    path = os.getcwd()\n",
    "    path = os.path.join(path, \"Houses Dataset\")\n",
    "    all_images = []\n",
    "    for i in df.index.values:\n",
    "        \n",
    "        imagepath = os.path.sep.join([path, \"{}_*\".format(i + 1)])\n",
    "        four_images = glob.glob(imagepath)\n",
    "        four_images = sorted(four_images)\n",
    "        \n",
    "        temp = []\n",
    "        collage = np.zeros((64, 64, 3), dtype=np.uint8)\n",
    "        \n",
    "        for image in four_images:\n",
    "            \n",
    "            img = cv2.imread(image)\n",
    "            img = cv2.resize(img, image_shape)\n",
    "            temp.append(img)\n",
    "            \n",
    "        collage[0:32, 0:32] = temp[0]\n",
    "        collage[0:32, 32:64] = temp[1]\n",
    "        collage[32:64, 32:64] = temp[2]\n",
    "        collage[32:64, 0:32] = temp[3]\n",
    "        \n",
    "        all_images.append(collage)\n",
    "        \n",
    "    all_images = np.array(all_images)\n",
    "    return all_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T18:46:24.334704Z",
     "start_time": "2019-04-29T18:46:24.325713Z"
    }
   },
   "outputs": [],
   "source": [
    "def greyscale(arr):\n",
    "    \n",
    "    v = []\n",
    "    for i in range(arr.shape[0]):\n",
    "    \n",
    "        gray = cv2.cvtColor(arr[i], cv2.COLOR_BGR2GRAY)\n",
    "        v.append(gray.flatten())\n",
    "\n",
    "    return np.array(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T19:57:47.821985Z",
     "start_time": "2019-04-29T19:57:47.814990Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_MLP(X_train_textual):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim=(X_train_textual.shape[1]), activation='relu'))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T19:29:12.556909Z",
     "start_time": "2019-04-29T19:29:12.549914Z"
    }
   },
   "outputs": [],
   "source": [
    "def Conv2DReluBatchNorm(n_filter, w_filter, h_filter, inputs):\n",
    "    return BatchNormalization()(Activation(activation='relu')(Conv2D(n_filter, (w_filter, h_filter), padding='same')(inputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T19:13:27.572791Z",
     "start_time": "2019-04-29T19:13:27.562802Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_CNN():\n",
    "    \n",
    "    model = Sequential()\n",
    "    inputs = Input(shape=(64, 64, 3))\n",
    "    \n",
    "    x = inputs\n",
    "    model = Conv2DReluBatchNorm(16, 3, 3, x)\n",
    "    model = Conv2DReluBatchNorm(32, 3, 3, model)\n",
    "    model = Conv2DReluBatchNorm(64, 3, 3, model)\n",
    "    \n",
    "    model = Flatten()(model)\n",
    "    model = Dense(16, activation='relu')(model)\n",
    "    model = BatchNormalization(axis=-1)(model)\n",
    "    model = Dropout(0.5)(model)\n",
    "    \n",
    "    model = Dense(4, activation='relu')(model)\n",
    "    model = Dense(1, activation='linear')(model)\n",
    "    \n",
    "    cnn = Model(inputs, model)\n",
    "\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-02T00:53:31.593Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def process_house_attributes(df, train, test):\n",
    "    \n",
    "    continuous = [\"num_bedrooms\", \"num_bathrooms\", \"area\"]\n",
    "\n",
    "    cs = MinMaxScaler()\n",
    "    trainContinuous = cs.fit_transform(train[continuous])\n",
    "    testContinuous = cs.transform(test[continuous])\n",
    " \n",
    "\n",
    "    zipBinarizer = LabelBinarizer().fit(df[\"zip_code\"])\n",
    "    trainCategorical = zipBinarizer.transform(train[\"zip_code\"])\n",
    "    testCategorical = zipBinarizer.transform(test[\"zip_code\"])\n",
    " \n",
    "\n",
    "    trainX = np.hstack([trainCategorical, trainContinuous])\n",
    "    testX = np.hstack([testCategorical, testContinuous])\n",
    " \n",
    "    return (trainX, testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T20:13:13.754448Z",
     "start_time": "2019-04-29T20:13:13.741454Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = [\"num_bedrooms\", \"num_bathrooms\", \"area\", \"zip_code\", \"price\"]\n",
    "dataset = pd.read_csv(\"HousesInfo.txt\", sep=\" \", header=None, names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T20:13:14.750536Z",
     "start_time": "2019-04-29T20:13:14.109846Z"
    }
   },
   "outputs": [],
   "source": [
    "dframe = remove_outliers(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T20:13:34.109453Z",
     "start_time": "2019-04-29T20:13:14.754477Z"
    }
   },
   "outputs": [],
   "source": [
    "images = read_images(dframe)\n",
    "images = images/np.max(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T20:13:34.182424Z",
     "start_time": "2019-04-29T20:13:34.113466Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_textual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T20:13:34.330340Z",
     "start_time": "2019-04-29T20:13:34.188420Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_textual, X_test_textual, X_train_images, X_test_images = train_test_split(dframe, images, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T20:13:34.718880Z",
     "start_time": "2019-04-29T20:13:34.333338Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_textual, X_test_textual = process_house_attributes(dframe, X_train_textual, X_test_textual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T20:14:42.086730Z",
     "start_time": "2019-04-29T20:14:42.079734Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_textual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T20:15:14.915677Z",
     "start_time": "2019-04-29T20:15:14.909680Z"
    }
   },
   "outputs": [],
   "source": [
    "maximum = np.max(X_train_textual[:, 9])\n",
    "y_train = X_train_textual[:, 9]/maximum\n",
    "y_test = X_test_textual[:, 9]/maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T20:15:16.590954Z",
     "start_time": "2019-04-29T20:15:15.906302Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_network = build_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T20:15:19.027684Z",
     "start_time": "2019-04-29T20:15:18.977710Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
    "cnn_network.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)\n",
    "cnn_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T20:15:19.727631Z",
     "start_time": "2019-04-29T20:15:19.691652Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp = build_MLP(X_train_textual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T20:15:21.575930Z",
     "start_time": "2019-04-29T20:15:21.538930Z"
    }
   },
   "outputs": [],
   "source": [
    "combined = concatenate([mlp.output, cnn_network.output])\n",
    "y = Dense(4, activation=\"relu\")(combined)\n",
    "y = Dense(1, activation=\"linear\")(y)\n",
    "model = Model(inputs=[mlp.input, cnn_network.input], outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T20:15:22.491883Z",
     "start_time": "2019-04-29T20:15:22.442933Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
    "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T20:30:08.137303Z",
     "start_time": "2019-04-29T20:15:24.616773Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit([X_train_textual, X_train_images], y_train,validation_split=0.2, epochs=25, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T19:56:20.528447Z",
     "start_time": "2019-04-29T19:56:14.674807Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = model.predict([X_test_textual, X_test_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T19:56:21.230585Z",
     "start_time": "2019-04-29T19:56:21.198605Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_cnn = r2_score(y_test, preds)\n",
    "mae_cnn = mean_absolute_error(y_test, preds)\n",
    "print(\"MAE for CNN+MLP\", mae_cnn)\n",
    "print(\"R2 for CNN+MLP\", r2_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T20:00:21.781651Z",
     "start_time": "2019-04-29T20:00:21.746670Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T20:00:42.958055Z",
     "start_time": "2019-04-29T20:00:42.918074Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_textual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
